import os
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings


def create_path_directory(path: str) -> str:
    directory = os.path.join(os.getcwd(), path)
    os.makedirs(directory, exist_ok=True)
    return directory

VECTORSTORE_DIRECTORY = create_path_directory("./database/vectorstore_glasshub")


# Step 1: Load the FAISS vectorstore
def load_vectorstore():
    if not os.path.isdir(VECTORSTORE_DIRECTORY):
        raise FileNotFoundError(
            f"âŒ Vectorstore directory '{VECTORSTORE_DIRECTORY}' not found.\n"
            "ğŸ’¡ Please run the ingestion script to generate the vector store."
        )
    
    print("ğŸ“¦ Loading vectorstore...")
    # sentence-transformers/all-MiniLM-L6-v2
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    db = FAISS.load_local(
        VECTORSTORE_DIRECTORY,
        embeddings,
        allow_dangerous_deserialization=True  # Needed if pickle was used during save
    )
    print("âœ… Vectorstore loaded successfully.")
    return db


# Step 2: Retrieve top-k most relevant documents
def retrieve_relevant_knowledge(
    user_question: str = "",
    is_licensed: str = "",
    license_type: str = "",
    service_type: str = "",
    regulations: str = "",
    k: int = 10
):
    db = load_vectorstore()

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…ÙˆØ³Ù‘Ø¹ Ù…Ù† Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    enriched_query = f"""
    Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_question}
    Ù‡Ù„ Ø§Ù„Ø±Ø®ØµØ© Ù…Ø±Ø®ØµØ©ØŸ â†’ {is_licensed}
    Ù†ÙˆØ¹ Ø§Ù„ØªØ±Ø®ÙŠØµ â†’ {license_type}
    Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© â†’ {service_type}
    Ø§Ù„ØªÙ†Ø¸ÙŠÙ…Ø§Øª â†’ {regulations}
    """

    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (FAISS)
    results = db.similarity_search(enriched_query.strip(), k=k)

    # Ø±Ø¨Ø· ÙƒÙ„ Ù†ØªÙŠØ¬Ø© Ø¨Ø§Ø³Ù… Ø§Ù„Ù…ØµØ¯Ø±
    formatted_results = []
    for doc in results:
        source = doc.metadata.get("source", "ğŸ“„ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
        content = doc.page_content.strip()
        formatted_results.append(f"ğŸ“„ **Ù…Ù† Ø§Ù„Ù…Ù„Ù:** {source}\n{content}")

    return "\n\n".join(formatted_results)




# For CLI Testing
if __name__ == "__main__":
    print("ğŸ” Welcome to the VMinds Knowledge Retriever!")
    while True:
        question = input("\nâ“ Enter your question (or type 'exit' to quit):\n> ")
        if question.strip().lower() == 'exit':
            print("ğŸ‘‹ Exiting.")
            break
        try:
            knowledge = retrieve_relevant_knowledge(question)
            if knowledge.strip():
                print("\nğŸ“š Retrieved Knowledge:")
                print(knowledge)
            else:
                print("âš ï¸ No relevant knowledge found.")
        except Exception as e:
            print(f"âŒ Error: {e}")
