
import json, re, os, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from langchain.schema import HumanMessage, AIMessage
from agent.custome_agent import MyCustomMultiImageChatLLM
from utils.helper_functions import parse_llm_response, parse_llm_response_pydantic
from rag.knowledge_retriever import retrieve_relevant_knowledge


# demo = https://qwen-vlm-a100.delightfulsky-f308bdb7.westus3.azurecontainerapps.io/qwen/generate_pdf
# main project = https://qwen-vlm-a100-glasshub.delightfulsky-f308bdb7.westus3.azurecontainerapps.io/qwen/generate_text

class Reports():

    def __init__(self, control_number, list_image_paths, controls_content):
        """
        Initializes the Reports class with control number and image paths.

        Args:
            control_number (str): The control number to be included in the report.
            list_image_paths (list): A list of image file paths to be included in the report.
            controls_content (str): full text of merged_controls.py
        """
        self.control_number = control_number
        self.list_image_paths = list_image_paths
        self.endpoint_url = "https://qwen-vlm-a100.delightfulsky-f308bdb7.westus3.azurecontainerapps.io/qwen/generate_pdf"
        self.controls_content = controls_content

    def generate_report(self):
        """
        Generates a report based on the provided control number and image paths.
        
        Args:
            control_number (str): The control number to be included in the report.
            image_paths (list): A list of image file paths to be included in the report.
            
        Returns:
            str: The generated report content.
        """
        endpoint_url = self.endpoint_url
        llm = MyCustomMultiImageChatLLM(endpoint_url=endpoint_url)

        # control_content = getattr(self.controls, 'control'+ self.control_number)
        pattern = rf'control_{self.control_number.strip()}\s*=\s*\"\"\"(.*?)\"\"\"'
        match = re.search(pattern, self.controls_content, re.DOTALL)

        if not match:
            raise ValueError(f"Control control_{self.control_number} not found in uploaded content.")

        control_content = match.group(1).strip()

        image_files = self.list_image_paths
        
        response = llm.invoke([HumanMessage(content=control_content)], image_paths=image_files)
        #print(response.content)
        return response.content


    def final_output_handling(self):
        """
        Extracts structured compliance information from the report generated by Images_report().
        
        Returns:
            dict: {
                "compliance": bool,
                "flags": list,
                "needsHumanReview": bool,
                "report": str
            }
        """
        report_text = self.generate_report()

        system_instruction = (
            "You are a JSON parser designed to extract structured compliance information from a report.\n"
            "Always return a valid JSON object with the following fields:\n"
            "- 'compliance_status': one of ['COMPLIANT', 'NON-COMPLIANT', 'INDECISIVE'] (uppercase)\n"
            "- 'flags': a list of strings such as issues or missing requirements\n"
            "  Example: 'flags': ['Missing documents', 'Additional proof needed']\n"
            "- 'Brief_report': a short summary (max 150 words)\n"
            "- 'needs_human_review': true or false\n"
            "- If you can't determine any field, use null (for strings), false (for booleans), and [] (for lists).\n\n"
            "If the report does not provide enough confidence to determine compliance, set compliance_status to 'INDECISIVE'.\n"
            "Return only the JSON object, nothing else.\n\n"
            f"Report:\n{report_text}"
        )
        print(f"system_instruction: {system_instruction}")
        llm = MyCustomMultiImageChatLLM(endpoint_url=self.endpoint_url)

        try:
            image_files = self.list_image_paths
            print(f"image_files: {image_files}")
            response = llm.invoke([HumanMessage(content=system_instruction)], image_paths=image_files)
            print(f"response: {response}")
            info = parse_llm_response(response.content, report_text)
            # final_result = llm.invoke([HumanMessage(content=result[report_text])])
            return {
                "compliance" : info.get("compliance_status", ""),
                "flags" : info.get("flags", []),
                "needs_review" : info.get("needs_human_review", False),
                "Brief_report" : info.get("Brief_report", ""),
                "report": report_text
            }

        except Exception as e:
            return {f"Error: {str(e)}"}
        
    def final_output_handling_parsing(self):
        """
        Extracts structured compliance information from the report generated by Images_report().

        Returns:
            dict: {
                "compliance": str,
                "flags": list,
                "needs_review": bool,
                "Brief_report": str,
                "report": str
            }
        """
        report_text = self.generate_report()

        # Instruction using proper JSON Schema style
        schema_instruction = (
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n\n"
            "As an example, for the schema "
            '{"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]},\n'
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema.\n"
            "The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n\n"
            "Here is the output schema:\n"
            "```\n"
            '{\n'
            '  "type": "object",\n'
            '  "properties": {\n'
            '    "compliance_status": {\n'
            '      "type": "string",\n'
            '      "description": "Compliance status: one of COMPLIANT, NON-COMPLIANT, INDECISIVE"\n'
            '    },\n'
            '    "flags": {\n'
            '      "type": "array",\n'
            '      "items": {"type": "string"},\n'
            '      "description": "List of issues or missing requirements"\n'
            '    },\n'
            '    "Brief_report": {\n'
            '      "type": "string",\n'
            '      "description": "Short summary of compliance analysis"\n'
            '    },\n'
            '    "needs_human_review": {\n'
            '      "type": "boolean",\n'
            '      "description": "Whether human review is needed"\n'
            '    }\n'
            '  },\n'
            '  "required": ["compliance_status", "flags", "Brief_report", "needs_human_review"]\n'
            '}\n'
            "```\n\n"
            f"Report:\n{report_text}"
        )

        print(f"[Instruction Sent to LLM]\n{schema_instruction}\n")

        llm = MyCustomMultiImageChatLLM(endpoint_url=self.endpoint_url)

        try:
            image_files = self.list_image_paths
            print(f"[Image Files]: {image_files}")
            
            # invoke model
            response = llm.invoke([HumanMessage(content=schema_instruction)], image_paths=image_files)
            print(f"[LLM Raw Response]: {response}")

            # Parse using your parsing function
            info = parse_llm_response_pydantic(response.content, report_text)

            # Return structured result
            return {
                "compliance": info.get("compliance_status", ""),
                "flags": info.get("flags", []),
                "needs_review": info.get("needs_human_review", False),
                "Brief_report": info.get("Brief_report", ""),
                "report": report_text
            }

        except Exception as e:
            print(f"[Error during report handling]: {e}")
            return {
                "error": str(e),
                "report": report_text
            }
