
import json, re, os, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from langchain.schema import HumanMessage, SystemMessage
from agent.custome_agent import MyCustomMultiImageChatLLM
from utils.helper_functions import parse_llm_response_pydantic
import logging
from typing import List, Dict, Optional

class old_Reports():

    def __init__(self, control_number, list_image_paths, controls_content, api):
        """
        Initializes the Reports class with control number and image paths.

        Args:
            control_number (str): The control number to be included in the report.
            list_image_paths (list): A list of image file paths to be included in the report.
            controls_content (str): full text of merged_controls.py
        """
        self.control_number = control_number
        self.list_image_paths = list_image_paths
        self.endpoint_url = api
        self.controls_content = controls_content

    def generate_report(self):
        """
        Generates a report based on the provided control number and image paths.
        
        Args:
            control_number (str): The control number to be included in the report.
            image_paths (list): A list of image file paths to be included in the report.
            
        Returns:
            str: The generated report content.
        """
        endpoint_url = self.endpoint_url
        llm = MyCustomMultiImageChatLLM(endpoint_url=endpoint_url)

        # control_content = getattr(self.controls, 'control'+ self.control_number)
        pattern = rf'{self.control_number.strip()}\s*=\s*\"\"\"(.*?)\"\"\"'
        match = re.search(pattern, self.controls_content, re.DOTALL)

        if not match:
            raise ValueError(f"Control {self.control_number} not found in uploaded content.")

        control_content = match.group(1).strip()

        image_files = self.list_image_paths
        
        response = llm.invoke([HumanMessage(content=control_content)], image_paths=image_files)
        #print(response.content)
        return response.content

    def final_output_handling_parsing(self):
        """
        Extracts structured compliance information from the report generated by Images_report().

        Returns:
            dict: {
                "compliance": str,
                "flags": list,
                "needs_review": bool,
                "Brief_report": str,
                "report": str
            }
        """
        report_text = self.generate_report()

        # Instruction using proper JSON Schema style
        schema_instruction = (
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n\n"
            "As an example, for the schema "
            '{"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]},\n'
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema.\n"
            "The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n\n"
            "Here is the output schema:\n"
            "```\n"
            '{\n'
            '  "type": "object",\n'
            '  "properties": {\n'
            '    "compliance_status": {\n'
            '      "type": "string",\n'
            '      "description": "Compliance status: one of COMPLIANT, NON-COMPLIANT, INDECISIVE"\n'
            '    },\n'
            '    "flags": {\n'
            '      "type": "array",\n'
            '      "items": {"type": "string"},\n'
            '      "description": "List of issues or missing requirements"\n'
            '    },\n'
            '    "Brief_report": {\n'
            '      "type": "string",\n'
            '      "description": "Short summary of compliance analysis"\n'
            '    },\n'
            '    "needs_human_review": {\n'
            '      "type": "boolean",\n'
            '      "description": "Whether human review is needed"\n'
            '    }\n'
            '  },\n'
            '  "required": ["compliance_status", "flags", "Brief_report", "needs_human_review"]\n'
            '}\n'
            "```\n\n"
            f"Report:\n{report_text}"
        )

        print(f"[Instruction Sent to LLM]\n{schema_instruction}\n")

        llm = MyCustomMultiImageChatLLM(endpoint_url=self.endpoint_url)

        try:
            image_files = self.list_image_paths
            print(f"[Image Files]: {image_files}")
            
            # invoke model
            response = llm.invoke([HumanMessage(content=schema_instruction)], image_paths=image_files)
            print(f"[LLM Raw Response]: {response}")

            # Parse using your parsing function
            info = parse_llm_response_pydantic(response.content, report_text)

            # Return structured result
            return {
                "compliance": info.get("compliance_status", ""),
                "flags": info.get("flags", []),
                "needs_review": info.get("needs_human_review", False),
                "Brief_report": info.get("Brief_report", ""),
                "report": report_text
            }

        except Exception as e:
            print(f"[Error during report handling]: {e}")
            return {
                "error": str(e),
                "report": report_text
            }




class Reports:
    def __init__(
        self,
        control_number: str,
        list_image_paths: List[str],
        controls_content: Dict,
        api: Optional[str] = None
    ):
        """
        Args:
            control_number (str): ID for the control.
            list_image_paths (List[str]): Paths to images to be sent to the LLM.
            controls_content (Dict): Structured control data.
            api (str): LLM API endpoint.
        """
        self.control_number = control_number
        self.image_paths = list_image_paths
        self.api = api

        # Extract structured content
        self.title = controls_content.get("title", "")
        self.description_control = controls_content.get("description_control", "")
        self.audit_instructions = controls_content.get("audit_instructions", "")
        self.clause_audit_instructions = controls_content.get("clause_audit_instructions", "")

        self.llm = MyCustomMultiImageChatLLM(endpoint_url=self.api)

        # Cache generated report
        self.report_text: Optional[str] = None

    def build_control_context(self) -> str:
        """Formats the control information for the LLM."""
        return (
            f"Control Number: {self.control_number}\n"
            f"Title: {self.title}\n"
            f"Description:\n{self.description_control}\n\n"
            f"Audit Instructions:\n{self.audit_instructions}\n"
        )

    def generate_report(self) -> str:
        """
        Sends the control context and images to the LLM to generate a report.
        Stores the result in self.report_text.

        Returns:
            str: Generated report content.
        """
        if self.report_text:  # avoid regenerating if already available
            return self.report_text

        try:
            messages = [
                SystemMessage(content=self.clause_audit_instructions),
                HumanMessage(content=self.build_control_context())
            ]
            response = self.llm.invoke(messages, image_paths=self.image_paths)
            self.report_text = response.content
            return self.report_text
        except Exception as e:
            logging.exception("Failed to generate report.")
            raise RuntimeError(f"Report generation failed: {e}")

    def parse_report_text(self) -> dict:
        """
        Parses the previously generated report using a structured schema.

        Returns:
            dict: Structured compliance report.
        """
        if not self.report_text:
            raise ValueError("No report text available. Please run generate_report() first.")

        schema_instruction = (
            "Return a JSON object conforming to this schema:\n"
            "{\n"
            '  "compliance_status": "COMPLIANT" | "NON-COMPLIANT" | "INDECISIVE",\n'
            '  "flags": ["..."],\n'
            '  "Brief_report": "short summary",\n'
            '  "needs_human_review": true | false\n'
            "}\n\n"
            f"Report:\n{self.report_text}"
        )

        try:
            response = self.llm.invoke([HumanMessage(content=schema_instruction)], image_paths=self.image_paths)
            info = parse_llm_response_pydantic(response.content, self.report_text)
            return {
                "compliance": info.get("compliance_status", ""),
                "flags": info.get("flags", []),
                "needs_review": info.get("needs_human_review", False),
                "Brief_report": info.get("Brief_report", ""),
                "report": self.report_text
            }
        except Exception as e:
            logging.exception("Error in parsing report.")
            return {"error": str(e), "report": self.report_text}

    def run_full_pipeline(self) -> dict:
        """
        Convenience method: runs report generation + parsing.

        Returns:
            dict: Final structured output with report.
        """
        self.generate_report()
        return self.parse_report_text()
